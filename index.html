<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="A one-stage whole-body mesh recovery method OSX and an upper-body dataset UBody.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TexVocab:Texture Vocabulary-conditioned Human Avatars</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h4 class="title conference-title is-4">CVPR 2024</h4>
            <h2 class="title is-2 publication-title">TexVocab:Texture Vocabulary-conditioned Human Avatars</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/zidonghua2018">Yuxiao Liu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/lizhe00">Zhe Li</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.liuyebin.com/">Yebin Liu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.sigs.tsinghua.edu.cn/whq_en/main.htm">Haoqian Wang</a><sup>1</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua University</span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                 <!--
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2303.16160" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <!--
                <span class="link-block">
                <a href="https://www.youtube.com/watch?v=s0cG3OVXQUo&t=2s" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
                 -->
                <!-- Code Link. -->
                 <!--
                <span class="link-block">
                  <a href="https://github.com/IDEA-Research/OSX" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                 -->
                <!-- Dataset Link. -->
                <!--
                <span class="link-block">
                  <a href="https://docs.google.com/forms/d/e/1FAIpQLSehgBP7wdn_XznGAM2AiJPiPLTqXXHw5uX9l7qeQ1Dh9HoO_A/viewform" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>  
                   -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h5 class="subtitle is-5">
           Given multi-view RGB videos of one character, we construct a texture vocabulary, and create realistic
animatable human avatars.
        </h5>
        <img src="./static/images/teaser.png" autoplay muted loop playsinline height="100%">
      </div>
    </div>
  </section>

  <p style="margin-bottom: -1.5cm;"></p>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              To adequately utilize the available image evidence in multi-view video-based avatar modeling, we propose TexVocab,
              a novel avatar representation that constructs a texture vocabulary and associates body poses with texture maps for animation. 
            </p>
            <p>
              Given multi-view RGB videos, our method initially back-projects all the available images in
              the training videos to the posed SMPL surface, producing texture maps in the SMPL UV domain. 
              Then we construct pairs of human poses and texture maps to establish a texture vocabulary for
              encoding dynamic human appearances under various poses. Unlike the commonly used joint-wise manner, 
              we further design a body-part-wise encoding strategy to learn the structural effects of the kinematic chain.
             </p>
            <p>
              Given a driving pose, we query the pose feature hierarchically by decomposing the pose vector 
              into several body parts and interpolating the texture features for synthesizing fine-grained human dynamics.
            </p>
            <p>
              Overall, our method is able to create animatable human avatars with detailed and dynamic appearances from RGB 
              videos, and the experiments show that our method outperforms state-of-the-art approaches.
            </p>
           
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <p style="margin-bottom: -0.5cm;"></p>

  <!-- <section class="hero">
    <div class="hero-body has-text-centered">
      <div class="container">
        <h3 class="title is-3">Method</h3>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item agora_1">
            <img src="./static/images/agora_1.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_2">
            <img src="./static/images/agora_2.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_3">
            <img src="./static/images/agora_3.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_4">
            <img src="./static/images/agora_4.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item agora_5">
            <img src="./static/images/agora_5.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_1">
            <img src="./static/images/ehf_1.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_2">
            <img src="./static/images/ehf_2.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_3">
            <img src="./static/images/ehf_3.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ehf_4">
            <img src="./static/images/ehf_4.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_1">
            <img src="./static/images/ubody_1.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_2">
            <img src="./static/images/ubody_2.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_3">
            <img src="./static/images/ubody_3.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_4">
            <img src="./static/images/ubody_4.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>

          <div class="item ubody_5">
            <img src="./static/images/ubody_5.png" class="interpolation-image"
              alt="Interpolation end reference image." />
          </div>


        </div>
        <h2 class="subtitle has-text-centered">
          From left to right: 1. Input, 2. ExPose, 3. Hand4Whoe, 4. OSX (Ours)
        </h2>
      </div>
    </div>
  </section> -->

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Comparisons with Other Methods</h3>
        <!-- <h3 class="title is-3 has-text-centered">UBody Dataset</h3> -->
        <p align="middle">
          <img src="./static/videos/agora.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          AGORA dataset. From left to right: 1. Input, 2. ExPose, 3. Hand4Whoe, 4. OSX (Ours)
        </h2>
 <div class="content has-text-justified">
            <p>
              To adequately utilize the available image evidence in multi-view video-based avatar modeling, we propose TexVocab,
              a novel avatar representation that constructs a texture vocabulary and associates body poses with texture maps for animation. 
            </p>
            <p>
              Given multi-view RGB videos, our method initially back-projects all the available images in
              the training videos to the posed SMPL surface, producing texture maps in the SMPL UV domain. 
              Then we construct pairs of human poses and texture maps to establish a texture vocabulary for
              encoding dynamic human appearances under various poses. Unlike the commonly used joint-wise manner, 
              we further design a body-part-wise encoding strategy to learn the structural effects of the kinematic chain.
             </p>
            <p>
              Given a driving pose, we query the pose feature hierarchically by decomposing the pose vector 
              into several body parts and interpolating the texture features for synthesizing fine-grained human dynamics.
            </p>
            <p>
              Overall, our method is able to create animatable human avatars with detailed and dynamic appearances from RGB 
              videos, and the experiments show that our method outperforms state-of-the-art approaches.
            </p>
           
          </div>
        
       <!-- <p align="middle">
          <img src="./static/videos/ehf.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          EHF dataset. From left to right: 1. Input, 2. ExPose, 3. Hand4Whoe, 4. OSX (Ours)
        </h2> -->

        <!-- 
        <p align="middle">
          <img src="./static/videos/ubody.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          UBody dataset. From left to right: 1. Input, 2. ExPose, 3. Hand4Whoe, 4. OSX (Ours)
        </h2>
        -->
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/demo_video.gif" type="video/mp4">
        </video> -->
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">UBody Dataset</h3>
        <h5 class="subtitle is-5">
          UBody is a large-scale Upper-Body dataset with the following annotations: 
          <style>
            ul {
              list-style-type: circle;
            }
          </style>
          <ul>
            <li>2D whole-body keypoints</li>
            <li>3D SMPLX annotations</li>
            <li>frame validity label </li>
            <li>person bbox, hand bbox </li>
          </ul>
        </h5>
        <p align="middle">
          <img src="./static/videos/demo_video.gif" width="720" height="240">
        </p>
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/demo_video.gif" type="video/mp4">
        </video> -->
      </div>
    </div>
  </section>

  <p style="margin-bottom: -0.5cm;"></p>
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h3 class="title is-3 has-text-centered">Example of 15 Scenes in UBody</h3>
        <!-- <h3 class="title is-3 has-text-centered">UBody Dataset</h3> -->
        <p align="middle">
          <img src="./static/videos/conductmusic.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          ConductMusic
        </h2>

        <p align="middle">
          <img src="./static/videos/conference.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Conference
        </h2>

        <p align="middle">
          <img src="./static/videos/entertainment.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Entertainment
        </h2>

        <p align="middle">
          <img src="./static/videos/fitness.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Fitness
        </h2>

        <p align="middle">
          <img src="./static/videos/interview.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Interview
        </h2>

        <p align="middle">
          <img src="./static/videos/livevlog.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          LiveVlog
        </h2>

        <p align="middle">
          <img src="./static/videos/magicshow.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          MagicShow
        </h2>

        <p align="middle">
          <img src="./static/videos/movie.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Movie
        </h2>

        <p align="middle">
          <img src="./static/videos/olympic.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Olympic
        </h2>

        <p align="middle">
          <img src="./static/videos/onlineclass.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          OnlineClass
        </h2>

        <p align="middle">
          <img src="./static/videos/signlanguage.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          SignLanguage
        </h2>

        <p align="middle">
          <img src="./static/videos/singing.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Singing
        </h2>

        <p align="middle">
          <img src="./static/videos/speech.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          Speech
        </h2>

        <p align="middle">
          <img src="./static/videos/tvshow.gif" width="720" height="240">
        </p>
        <h2 class="subtitle has-text-centered">
          TVShow
        </h2>

      </div>
    </div>
  </section>

  <p style="margin-bottom: -1.5cm;"></p>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content is-size-6">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{liu2024texvocab,
  author    = {Yuxiao, Liu and Zhe, Li and Yebin, Liu and Haoqian, Wang},
  title     = {TexVocab:Texture Vocabulary-conditioned Human Avatars},
  journal   = {CVPR},
  year      = {2024},
}</code></pre>
<h2 class="title">Contact Us</h2>
<style>
  ul {
    list-style-type: circle;
  }
</style>
<ul>
  <li>For detailed questions about this work, please contact Yuxiao Liu (liuyuxia22@mails.tsinghua.edu.cn).</li>
  <li>We are looking for talented, motivated, and creative research and engineering interns working on human-centric visual understanding and generation topics. If you are interested, please send your CV to Haoqian Wang (wangyizhai@sz.tsinghua.edu.cn).</li>
</ul>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-size-6">
          <div class="content">
            <p>
              This website is created with this <a href="https://nerfies.github.io/">template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
